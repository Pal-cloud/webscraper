# Django WebScraper con Selenium y Firefox

Un proyecto de web scraping desarrollado con Django y Selenium, utilizando Firefox como navegador headless dentro de un entorno Docker.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema de web scraping que utiliza:
- **Django** como framework web
- **Selenium** para la automatizaciÃ³n del navegador
- **Firefox ESR** como navegador headless
- **GeckoDriver** para la comunicaciÃ³n con Firefox
- **Docker** para el entorno de desarrollo y producciÃ³n

## ğŸš€ CaracterÃ­sticas

- Web scraping automatizado con Selenium
- Navegador headless (sin interfaz grÃ¡fica)
- Entorno dockerizado para consistencia
- ConfiguraciÃ³n optimizada para servidores
- Manejo de errores y debugging

## ğŸ“ Estructura del Proyecto

```
webscraper_project/
â”œâ”€â”€ manage.py                 # Django management script
â”œâ”€â”€ requirements.txt          # Dependencias de Python
â”œâ”€â”€ docker-compose.yml        # ConfiguraciÃ³n de Docker Compose
â”œâ”€â”€ Dockerfile               # Imagen Docker personalizada
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ webscraper_project/     # ConfiguraciÃ³n principal de Django
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ wsgi.py
â””â”€â”€ scraper/               # AplicaciÃ³n de scraping
    â””â”€â”€ services/
        â””â”€â”€ scrape.py      # LÃ³gica principal de scraping
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.11**
- **Django 5.2.10**
- **Selenium 4.40.0**
- **Firefox ESR**
- **GeckoDriver v0.35.0**
- **Docker & Docker Compose**

## ğŸ“¦ InstalaciÃ³n

### OpciÃ³n 1: Con Docker (Recomendado)

```bash
# Clonar el repositorio
git clone <repository-url>
cd webscraper_project

# Construir y ejecutar con Docker Compose
docker-compose up --build
```

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Instalar dependencias
pip install -r requirements.txt

# Ejecutar migraciones
python manage.py migrate

# Ejecutar servidor de desarrollo
python manage.py runserver
```

## ğŸ¯ Uso

El mÃ³dulo principal de scraping se encuentra en `scraper/services/scrape.py`. Ejemplo de uso:

```python
from scraper.services.scrape import scrape_website

# Ejecutar scraping
data = scrape_website()
print(data)
```

## ğŸ“š Docker

Para informaciÃ³n detallada sobre el setup de Docker, consulta la documentaciÃ³n especÃ­fica en la secciÃ³n Docker de este proyecto.

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.